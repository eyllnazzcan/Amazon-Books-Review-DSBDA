{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a80b3a-7dfa-4a67-92db-033ed7c080be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil, time, glob\n",
    "import subprocess, time, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d83515-3ebc-4046-baee-28670d73ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two directories for organizing files and preparing for streaming into HDFS\n",
    "os.makedirs(\"streaming_folder\", exist_ok=True)\n",
    "os.makedirs(\"parts\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d06a27-96e0-4ba8-b387-d31b020a4b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created parts/part_0.csv\n",
      "Created parts/part_1.csv\n",
      "Created parts/part_2.csv\n",
      "Created parts/part_3.csv\n",
      "Created parts/part_4.csv\n",
      "Created parts/part_5.csv\n",
      "Created parts/part_6.csv\n",
      "Created parts/part_7.csv\n",
      "Created parts/part_8.csv\n",
      "Created parts/part_9.csv\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file in chunks and writes the data into smaller files\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(\"clean_books_10k.csv\", chunksize=chunk_size)):\n",
    "    out_file = f\"parts/part_{i}.csv\"\n",
    "    # Only the first chunk writes header\n",
    "    chunk.to_csv(out_file, index=False, header=(i==0))\n",
    "    print(f\"Created {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f857b1-24e2-477a-84b2-57640c04394d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 01:49:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied parts/part_0.csv to streaming folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 01:49:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied parts/part_1.csv to streaming folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 01:49:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied parts/part_2.csv to streaming folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 01:50:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied parts/part_3.csv to streaming folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 01:50:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied parts/part_4.csv to streaming folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 01:50:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied parts/part_5.csv to streaming folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 01:50:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied parts/part_6.csv to streaming folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 01:50:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied parts/part_7.csv to streaming folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 01:51:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied parts/part_8.csv to streaming folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 01:51:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied parts/part_9.csv to streaming folder\n"
     ]
    }
   ],
   "source": [
    "# Upload the chunks into HDFS in a simulated streaming fashion\n",
    "hdfs_streaming_path = \"hdfs://localhost:54310/user/ubuntu/streaming_input/\"\n",
    "\n",
    "\n",
    "parts = sorted(glob.glob(\"parts/part_*.csv\"))\n",
    "\n",
    "for p in parts:\n",
    "    subprocess.run([\"hdfs\", \"dfs\", \"-put\", \"-f\", p, hdfs_streaming_path])\n",
    "    print(f\"Copied {p} to streaming folder\")\n",
    "    # 10 secs delay between each upload to mimic the streaming of real-time data ingestion\n",
    "    time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
